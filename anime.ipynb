{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting Anime Ratings using Matrix Factorization in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy import sparse\n",
    "import plotly.express as px\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a total of 69600 users and 9927 anime. There are 6337241 ratings provided (out of 690,919,200 possible ratings)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem Statement\n",
    "Given a set of user ratings for anime, predict the rating for each user-anime pair."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Exploration\n",
    "Anime Recommendations Database from [Kaggle](https://www.kaggle.com/CooperUnion/anime-recommendations-database).\n",
    "We see that there are lots of rows with a rating of -1 , indicating missing ratings, we can get rid of these rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id  anime_id  rating\n",
      "0        1        20      -1\n",
      "1        1        24      -1\n",
      "2        1        79      -1\n",
      "3        1       226      -1\n",
      "4        1       241      -1\n"
     ]
    }
   ],
   "source": [
    "anime_ratings_df = pd.read_csv(\"rating.csv\")\n",
    "anime_ratings_df.shape\n",
    "print(anime_ratings_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the rating distribution\n",
    "fig = px.histogram(anime_ratings_df,x=\"rating\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rating</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-1</th>\n",
       "      <td>1476496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>41453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>104291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>282806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>637775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1375287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1646019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1254096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>955715</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         rating\n",
       "rating         \n",
       "-1      1476496\n",
       " 1        16649\n",
       " 2        23150\n",
       " 3        41453\n",
       " 4       104291\n",
       " 5       282806\n",
       " 6       637775\n",
       " 7      1375287\n",
       " 8      1646019\n",
       " 9      1254096\n",
       " 10      955715"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# describe the distribution\n",
    "anime_ratings_df.groupby([\"rating\"]).agg({\"rating\":\"count\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets remove all the -1 rating  which means there is no rating\n",
    "anime_ratings_df = anime_ratings_df.loc[anime_ratings_df[\"rating\"]!= -1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91.05231321839081"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Average number of ratings per user\n",
    "np.mean(anime_ratings_df.groupby(['user_id']).count()['anime_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, valid_df = train_test_split(anime_ratings_df, test_size=0.2)\n",
    "\n",
    "#resetting indices to avoid indexing errors in the future\n",
    "train_df = train_df.reset_index()[['user_id', 'anime_id', 'rating']]\n",
    "valid_df = valid_df.reset_index()[['user_id', 'anime_id', 'rating']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess\n",
    "##### Encoding columns with continuous ids\n",
    "Because we'll be using PyTorch's embedding layers to create our user and item embeddings, we need continuous IDs to be able to index into the embedding matrix and access each user/item embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_column(column):\n",
    "    \"\"\" Encodes a pandas column with continous IDs\"\"\"\n",
    "    keys = column.unique()\n",
    "    key_to_id = {key:idx for idx,key in enumerate(keys)}\n",
    "    return key_to_id, np.array([key_to_id[x] for x in column]), len(keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_df(anime_df):\n",
    "    \"\"\"Encodes rating data with continuous user and anime ids\"\"\"\n",
    "    \n",
    "    anime_ids, anime_df['anime_id'], num_anime = encode_column(anime_df['anime_id'])\n",
    "    user_ids, anime_df['user_id'], num_users = encode_column(anime_df['user_id'])\n",
    "    return anime_df, num_users, num_anime, user_ids, anime_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users : 68816\n",
      "Number of anime : 9737\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>anime_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  anime_id  rating\n",
       "0        0         0      10\n",
       "1        1         1      10\n",
       "2        2         2       9\n",
       "3        3         3       8\n",
       "4        4         4       7"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anime_df, num_users, num_anime, user_ids, anime_ids = encode_df(train_df)\n",
    "print(\"Number of users :\", num_users)\n",
    "print(\"Number of anime :\", num_anime)\n",
    "anime_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our goal is to find the optimal embeddings for each user and each item. We can then use these embeddings to make predictions for any user-item pair by taking the dot product of user embedding and item embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initializing user and item embeddings\n",
    "def create_embeddings(n, K):\n",
    "    \"\"\"\n",
    "    Creates a random numpy matrix of shape n, K with uniform values in (0, 11/K)\n",
    "    n: number of items/users\n",
    "    K: number of factors in the embedding \n",
    "    \"\"\"\n",
    "    return 11*np.random.random((n, K)) / K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating Sparse utility matrix: Since our cost function needs the utility matrix, we need a function to create this matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating sparse utility matrix\n",
    "def create_sparse_matrix(df, rows, cols, column_name=\"rating\"):\n",
    "    \"\"\" Returns a sparse utility matrix\"\"\" \n",
    "    return sparse.csc_matrix((df[column_name].values,(df['user_id'].values, df['anime_id'].values)),shape=(rows, cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "anime_df, num_users, num_anime, user_ids, anime_ids = encode_df(train_df)\n",
    "Y = create_sparse_matrix(anime_df, num_users, num_anime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### making predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(df, emb_user, emb_anime):\n",
    "    \"\"\" This function computes df[\"prediction\"] without doing (U*V^T).\n",
    "    \n",
    "    Computes df[\"prediction\"] by using elementwise multiplication of the corresponding embeddings and then \n",
    "    sum to get the prediction u_i*v_j. This avoids creating the dense matrix U*V^T.\n",
    "    \"\"\"\n",
    "    df['prediction'] = np.sum(np.multiply(emb_anime[df['anime_id']],emb_user[df['user_id']]), axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient Descent:\n",
    "I’ve used momentum implementation I found online."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(df, emb_user, emb_anime):\n",
    "    \"\"\" Computes mean square error\"\"\"\n",
    "    Y = create_sparse_matrix(df, emb_user.shape[0], emb_anime.shape[0])\n",
    "    predicted = create_sparse_matrix(predict(df, emb_user, emb_anime), emb_user.shape[0], emb_anime.shape[0], 'prediction')\n",
    "    return np.sum((Y-predicted).power(2))/df.shape[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient(df, emb_user, emb_anime):\n",
    "    \"\"\" Computes the gradient for user and anime embeddings\"\"\"\n",
    "    Y = create_sparse_matrix(df, emb_user.shape[0], emb_anime.shape[0])\n",
    "    predicted = create_sparse_matrix(predict(df, emb_user, emb_anime), emb_user.shape[0], emb_anime.shape[0], 'prediction')\n",
    "    delta =(Y-predicted)\n",
    "    grad_user = (-2/df.shape[0])*(delta*emb_anime) + 2*lmbda*emb_user\n",
    "    grad_anime = (-2/df.shape[0])*(delta.T*emb_user) + 2*lmbda*emb_anime\n",
    "    return grad_user, grad_anime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(df, emb_user, emb_anime, iterations=2000, learning_rate=0.01, df_val=None):\n",
    "    \"\"\" \n",
    "    Computes gradient descent with momentum (0.9) for given number of iterations.\n",
    "    emb_user: the trained user embedding\n",
    "    emb_anime: the trained anime embedding\n",
    "    \"\"\"\n",
    "    Y = create_sparse_matrix(df, emb_user.shape[0], emb_anime.shape[0])\n",
    "    beta = 0.9\n",
    "    grad_user, grad_anime = gradient(df, emb_user, emb_anime)\n",
    "    v_user = grad_user\n",
    "    v_anime = grad_anime\n",
    "    for i in range(iterations):\n",
    "        grad_user, grad_anime = gradient(df, emb_user, emb_anime)\n",
    "        v_user = beta*v_user + (1-beta)*grad_user\n",
    "        v_anime = beta*v_anime + (1-beta)*grad_anime\n",
    "        emb_user = emb_user - learning_rate*v_user\n",
    "        emb_anime = emb_anime - learning_rate*v_anime\n",
    "        if(not (i+1)%50):\n",
    "            print(\"\\niteration\", i+1, \":\")\n",
    "            print(\"train mse:\",  cost(df, emb_user, emb_anime))\n",
    "            if df_val is not None:\n",
    "                print(\"validation mse:\",  cost(df_val, emb_user, emb_anime))\n",
    "    return emb_user, emb_anime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "iteration 50 :\n",
      "train mse: 16.079377855501587\n"
     ]
    }
   ],
   "source": [
    "lmbda = 0.0002\n",
    "emb_user = create_embeddings(num_users, 3)\n",
    "emb_anime = create_embeddings(num_anime, 3)\n",
    "emb_user, emb_anime = gradient_descent(anime_df, emb_user, emb_anime, iterations=800, learning_rate=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### making prediction on test data\n",
    "based solely on similarities between user behaviors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_new_data(valid_df, user_ids, anime_ids):\n",
    "    \"\"\" Encodes valid_df with the same encoding as train_df.\n",
    "    \"\"\"\n",
    "    df_val_chosen = valid_df['anime_id'].isin(anime_ids.keys()) & valid_df['user_id'].isin(user_ids.keys())\n",
    "    valid_df = valid_df[df_val_chosen]\n",
    "    valid_df['anime_id'] =  np.array([anime_ids[x] for x in valid_df['anime_id']])\n",
    "    valid_df['user_id'] = np.array([user_ids[x] for x in valid_df['user_id']])\n",
    "    return valid_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"before encoding:\", valid_df.shape)\n",
    "valid_df = encode_new_data(valid_df, user_ids, anime_ids)\n",
    "print(\"after encoding:\", valid_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mse = cost(train_df, emb_user, emb_anime)\n",
    "val_mse = cost(valid_df, emb_user, emb_anime)\n",
    "print(train_mse, val_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#looking at the predictions\n",
    "valid_df[10:30].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "98dd0d925914c31592b8162606cb7cf76290f166a5dc140582b0ccf1d4170e5d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
